#!/usr/bin/env python3
import argparse
import os
import re
from pathlib import Path

BANNED_SOFT_WORDS = [
    "ì—´ì‹¬íˆ", "ì„±ì‹¤", "ì±…ì„ê°", "ìµœì„ ì„", "ë‹¤ì–‘í•œ ê²½í—˜", "ë§ì€ ê²½í—˜",
    "ë¬¸ì œ í•´ê²° ëŠ¥ë ¥", "ì»¤ë®¤ë‹ˆì¼€ì´ì…˜ ëŠ¥ë ¥", "í˜‘ì—… ëŠ¥ë ¥", "ì„±ì¥", "ë„ì „"
]

ACTION_VERBS = [
    "ê°œì„ ", "ìµœì í™”", "ì„¤ê³„", "êµ¬ì¶•", "ë„ì…", "ìë™í™”", "ë¦¬íŒ©í„°ë§", "ë¶„ì„", "ìš´ì˜", "ë°°í¬", "ì „í™˜", "ê°ì†Œ", "ì¦ê°€"
]

METRIC_PATTERN = re.compile(r"(\d+\s*%|\d+\s*(ms|ì´ˆ|ë¶„|ì‹œê°„|ê±´|ê°œ|ëª…|íšŒ|ë°°|ì›)|[0-9]+\.[0-9]+)")


def read_files_from_list(file_path: Path):
    if not file_path.exists():
        return []
    return [line.strip() for line in file_path.read_text(encoding="utf-8").splitlines() if line.strip()]


def analyze_html(path: Path):
    text = path.read_text(encoding="utf-8", errors="ignore")
    lowered = text.lower()

    issues = []
    warnings = []
    score = 100

    # Basic SEO/structure checks
    if "<title" not in lowered:
        issues.append("`<title>` íƒœê·¸ ì—†ìŒ")
        score -= 12
    if "name=\"description\"" not in lowered and "name='description'" not in lowered:
        warnings.append("meta description ì—†ìŒ")
        score -= 5
    if "<h1" not in lowered:
        issues.append("`<h1>` íƒœê·¸ ì—†ìŒ")
        score -= 10

    # Accessibility checks
    img_count = len(re.findall(r"<img\b", lowered))
    alt_count = len(re.findall(r"<img\b[^>]*\balt=", lowered))
    if img_count > 0 and alt_count < img_count:
        missing = img_count - alt_count
        issues.append(f"ì´ë¯¸ì§€ alt ëˆ„ë½: {missing}ê°œ")
        score -= min(20, 4 * missing)

    if "<html" in lowered and "lang=" not in lowered:
        warnings.append("`<html lang=...>` ëˆ„ë½")
        score -= 5

    # Career-document quality checks
    metric_hits = METRIC_PATTERN.findall(text)
    metric_count = len(metric_hits)
    if metric_count == 0:
        issues.append("ì„±ê³¼ ìˆ˜ì¹˜(%, ì‹œê°„, ê±´ìˆ˜ ë“±) ê·¼ê±°ê°€ ì—†ìŒ")
        score -= 16
    elif metric_count < 3:
        warnings.append("ì„±ê³¼ ìˆ˜ì¹˜ê°€ ì ìŒ (3ê°œ ë¯¸ë§Œ)")
        score -= 6

    soft_hits = [w for w in BANNED_SOFT_WORDS if w in text]
    if soft_hits:
        warnings.append("ëª¨í˜¸/ì•½í•œ í‘œí˜„ í¬í•¨: " + ", ".join(sorted(set(soft_hits))[:6]))
        score -= min(12, len(set(soft_hits)) * 2)

    action_hits = sum(1 for v in ACTION_VERBS if v in text)
    if action_hits < 3:
        warnings.append("í–‰ë™ ì¤‘ì‹¬ ë™ì‚¬ ë¹„ìœ¨ ë‚®ìŒ (ê°œì„ /ìµœì í™”/êµ¬ì¶• ë“±)")
        score -= 5

    # Link hygiene
    for m in re.finditer(r"<a\b[^>]*href=[\"']([^\"']+)[\"']", text, re.IGNORECASE):
        href = m.group(1).strip()
        if href.startswith("#") or href.startswith("mailto:") or href.startswith("tel:"):
            continue
        if href in {"", "javascript:void(0)", "javascript:;"}:
            issues.append("ìœ íš¨í•˜ì§€ ì•Šì€ ë§í¬ href ë°œê²¬")
            score -= 8
            break

    return max(score, 0), issues, warnings


def analyze_css(path: Path):
    text = path.read_text(encoding="utf-8", errors="ignore")
    issues = []
    warnings = []
    score = 100

    # Basic maintainability checks
    if "!important" in text:
        count = text.count("!important")
        warnings.append(f"`!important` ì‚¬ìš© {count}íšŒ")
        score -= min(10, count)

    if re.search(r"font-size\s*:\s*\d+px", text):
        warnings.append("px ê³ ì • í°íŠ¸ ì‚¬ì´ì¦ˆ ì‚¬ìš© (ë°˜ì‘í˜•/ì ‘ê·¼ì„± ì•½í™” ê°€ëŠ¥)")
        score -= 4

    if len(text.splitlines()) > 1200:
        warnings.append("CSS íŒŒì¼ ê¸¸ì´ í¼: ë¶„ë¦¬/ëª¨ë“ˆí™” ê²€í†  í•„ìš”")
        score -= 4

    return max(score, 0), issues, warnings


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--files-file", required=True)
    parser.add_argument("--output", required=True)
    args = parser.parse_args()

    files = read_files_from_list(Path(args.files_file))

    critical = 0
    total_score = 0
    reviewed = 0
    lines = ["# ğŸ” Strict Content Review", ""]

    for rel in files:
        p = Path(rel)
        if not p.exists() or p.is_dir():
            continue

        ext = p.suffix.lower()
        if ext not in {".html", ".css"}:
            continue

        reviewed += 1
        if ext == ".html":
            score, issues, warnings = analyze_html(p)
        else:
            score, issues, warnings = analyze_css(p)

        total_score += score
        if score < 70 or len(issues) >= 2:
            critical += 1

        status = "âŒ FAIL" if score < 70 else ("âš ï¸ WARN" if score < 85 else "âœ… PASS")
        lines.append(f"## {status} `{rel}` â€” {score}/100")

        if issues:
            lines.append("**ì¹˜ëª… ì´ìŠˆ**")
            for i in issues:
                lines.append(f"- {i}")
        if warnings:
            lines.append("**ê°œì„  í¬ì¸íŠ¸**")
            for w in warnings:
                lines.append(f"- {w}")
        if not issues and not warnings:
            lines.append("- ì ê²€ ê¸°ì¤€ í†µê³¼")
        lines.append("")

    if reviewed == 0:
        lines.append("ë¦¬ë·°í•  HTML/CSS íŒŒì¼ì´ ì—†ìŒ.")
        Path(args.output).write_text("\n".join(lines), encoding="utf-8")
        return

    avg = round(total_score / reviewed, 1)
    lines.append("---")
    lines.append(f"- í‰ê·  ì ìˆ˜: **{avg}/100**")
    lines.append(f"- ì¹˜ëª… ìƒíƒœ íŒŒì¼ ìˆ˜: **{critical}ê°œ**")
    lines.append("")
    lines.append("íŒì • ê¸°ì¤€: 70ì  ë¯¸ë§Œ ë˜ëŠ” ì¹˜ëª… ì´ìŠˆ ë‹¤ìˆ˜ë©´ ì‹¤íŒ¨ ì²˜ë¦¬")

    Path(args.output).write_text("\n".join(lines), encoding="utf-8")

    # Fail the workflow when strict gate is not met
    if critical > 0 or avg < 80:
        raise SystemExit(1)


if __name__ == "__main__":
    main()
